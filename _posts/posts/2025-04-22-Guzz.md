---
title:   "Guzz: When debugging meets fuzzing - A journey into automated harness generation"
classes: wide
header:
  teaser: /img/postcover/earth.png
ribbon: green
categories:
  - Projects
toc: true
toc_label: "From GDB to fuzzing: Automating the impossible"
---


> Especially for MSc Computer Security students (and other interested students), an
> alternative assignment is possible, related to fuzz testing. In this assignment,
> students design and implement improvements to the AFL++ fuzzer.
> To chose this alternative means the above mentioned objectives wont be met since
> the goals of this particular assignment are:
> To gain practical experience using AFL++ to test software
> To gain understanding on how fuzzers can (fail to) reach or trigger certain software bugs
> To gain practical experience in fuzzer development and evaluation
> To gain experience in automated vulnerability research
> To learn how to present research results, both orally and in writing

CAP.


"See you next week with your proposal."

That's how our research project began. Our only input from the professor was:
find something interesting and novel that could advance the fuzzing field, with
potential for future publication. 

We had to identify an idea worthy of publication AND develop it in
just four weeks – including the time spent finding the idea itself.

After days of tossing ideas back and forth, one of my teammates stumbled upon a
nice idea: a Black Hat 2019 talk called ["What the Fuzz"](https://youtu.be/Wy7qY5ms3qY?si=NccTPOe9o0PmEPUu&t=1410).
At minute 23:40, the presenters casually mentioned, "wouldn't it be nice if..."
and showed mockups of a hypothetical tool that could:
- Reach a specific state in GDB
- Set fuzzing parameters like buffer locations
- Start fuzzing from that exact point
- Restore the original state when done

![alt]({{ site.url }}{{ site.baseurl }}/assets/images/imgs/guzz1.png)


After 10 days of searching, we had our project. Now we faced an even bigger
challenge: develop it.
We had roughly 20 days to turn this "wouldn't it be nice" idea into reality.

> **Core idea**
> 1. Debug your way to the interesting function
> 2. Snapshot the entire process state
> 3. Hand it off to a fuzzer
> 4. Get results
> 5. Restore gdb status


# The Three Implementations: A Tale of Trade-offs

Due to the nature of the project, we initially split up, with each of us
pursuing our own ideas and approaches — though we still worked closely together.
Every couple of days, we would regroup to review what was working and what
wasn’t, helping us decide how to allocate our efforts. This process led to three
main ideas and their corresponding implementations. While each of us focused on
our own direction, we also contributed to each other's work, helping out as
needed. Some ideas emerged as fixes to issues discovered while developing
earlier ones, so everyone touched everything.

Just to throw out some stats:
```
~/c/Guzz [main] λ gshowstats

    archMaster: 155 commits
        Added: 186355  Removed: 985  Net: 185370
    grizzly: 165 commits
        Added: 9163  Removed: 190216  Net: -181053
    surferBoy: 123 commits
        Added: 5712  Removed: 2320  Net: 3392
```

Yes, yes someone messed up and added `.venv` folder to a commit:
```
commit 6b0f...
Author: archMaster
Date:   Wed Jun 26 13:16:02 2024 +0200

    add venv; add correct afl install; add bootstrap script

    ...
    ...

    1033 files changed, 183403 insertions(+), 91 deletions(-)

```

and someone removed them 
```
commit 8a93...
Author: grizzly
Date:   Wed Jun 26 13:25:38 2024 +0200

    venv in gitignore

    .gitignore  |    1 +
    ...
    ...
    ...

    1028 files changed, 1 insertion(+), 183344 deletions(-)
```

But this is irrelevant to the story, was just a bit of context for those messed
up stats.

In the end we ended up with a python gdb plugin that served as interface which
integrated all our proposed solutions and their capabilities.

## Implementation 1: QEMU Memory Dump

Our first approach seemed straightforward - dump everything and reload it in
QEMU. We created our own executable format (cause if you don't have a custom
format u're a nobody) and dove into the AFL++ codebase.

The implementation required us to:
1. Create a custom dump format that captured memory regions and registers
2. Patch AFL++ and QEMU to recognize and load our format
3. Handle the myriad edge cases that come with memory management


The biggest challenge? Address space compatibility. When you dump a process
mid-execution, all those carefully resolved GOT entries are pointing to specific
addresses. Load that dump in QEMU with a different memory layout, and suddenly
you're playing Russian roulette with segfaults.  
What? File descriptors? Forget it. I said _forget it_.

## Tech talks (feel free to skip it)

When implementing our QEMU approach, we faced several interesting challenges.
The first was address space compatibility - since QEMU loads executables with a
fixed load bias of 0x40000000, while GDB uses different load addresses, we
couldn't simply copy memory as-is. All those carefully resolved GOT table
entries would point to the wrong places!

To solve this, we created a custom executable format that captures both memory
regions and register values. The format includes headers with start/end
addresses, protection flags, and region sizes, followed by the actual memory
data and register values.

We patched AFL++'s QEMU mode to understand this format, which required modifying
both AFL++ and QEMUafl. The `check_binary()` function in AFL++ needed updating,
and we added a custom `load_elf_dump()` function in qemuafl/linux-user/elfload.c
to handle our format.

One tricky part was handling CPU capabilities. Modern binaries often use
CPU-specific instructions, but our emulated CPU didn't support all of them. When
the program tried to use these instructions in QEMU, we'd get illegal
instruction errors. We solved this by leveraging the hwcaps environment
variables to disable unsupported capabilities before running the executable.

Another headache was the fs_base segment register. This register is crucial for
stack canary checks (those values that protect against buffer overflows), and
QEMU normally initializes segment registers to zero. We had to explicitly load
our dumped value to prevent segfaults during canary checks.

The final integration with our GDB plugin required setting up buffer locations
for the fuzzer to place input, which we implemented through persistent mode
hooks. Essentially, we're telling AFL++ exactly where in memory to place the
mutated input for testing.

This approach gives us perfect memory and register state replication, but the
cost is high disk usage (dumping an entire process can be massive) and those
pesky file descriptor/socket issues I mentioned earlier.


### The Good, The Bad, and The Ugly

**The Good:**  
- Perfect memory and register state replication
- In-memory fuzzing capabilities
- Works with any binary (in theory)

**The Bad:**  
- No file descriptor transfer (RIP sockets and files)
- Massive disk usage (dumping entire process memory isn't cheap)
- Address space mismatches causing endless headaches

**The Ugly:**  

We had to disable CPU capabilities because our emulated CPU didn't
support all the fancy instructions the host CPU did. Cue hours of debugging
illegal instruction errors.

## Implementation 2: ZAFL - The Static Rewriting Adventure

Frustrated with QEMU's limitations, we turned to ZAFL (Zipr-based AFL).
The premises were appealing enough - near-native performance with static
instrumentation.

### The Architecture

ZAFL workflow is nothing magic:
It performs a binary code lifting to an IR (intermediate representation), it
applies AFL instrumentation and simply rewrites the binary with all the newly
added fuzzing utilities that are now baked into the binary.


Our plan was clever (we thought):
1. Fork from GDB
2. Exec the ZAFL-instrumented binary
3. Replicate the process main binary state
4. Start fuzzing

### Tech talks (feel free to skip it) (fix me this section)

Remember those problematic pointers I mentioned?

The new binary layout is clearly not the same as the original one, and **CLEARLY**
all the addresses are now no longer correct.

Consider a simple C program:
```c
int add(int a, int b) {
    return a + b;
}

int main() {
    int (*add_ptr)(int, int);
    add_ptr = &add;
    int result = add_ptr(5, 3);
    return 0;
}
```

In this example, the address of add_ptr could get
placed on the stack as following on X86-64:

```asm
; rax will become an absolute address.
lea rax,[rip+0xffffffffffffffdd]
mov QWORD PTR [rbp-0x8],rax
```

After statically instrumenting the program with ZAFL, the absolute address
stored in memory could become incorrect. We considered analyzing both the
uninstrumented and instrumented program with Ghidra to ﬁnd ways to patch
(data) memory to contain correct code pointers, but at the same time, we learned
about Frida. As Frida is able to attach to running processes and is able to
dynamically instrument the binary for fuzzing, we decided to prioritise
exploring this approach instead. That way, we can contribute a wider overview of
techniques that might suit our use case best and the practical challenges that
may arise when actually implementing these approaches.

We included code in our AFL++ patches that attempts to replace the segments,
however, in our ﬁnal submission we have commented this out as it caused more
errors than it ﬁxed. Therefore, our current ZAFL implementation only preserves
general purpose register state taken, which is limited. Again, this relates to
our decision to prioritize exploring an additional implementation that employs
Frida.


## Implementation 3: Frida - Dynamic Instrumentation

As explained in the previous chapter (that you might've skipped), dynamic
instrumentation meant no binary rewriting, no address relocation nightmares.

### The Clever Hack

We couldn't attach Frida directly to our GDB target (ptrace limitations), so we
decided to simply fork... easier said than done.
At this point we're couple days away from the deadline but our crazy @surferBoy
(with some of me contribution, but he the crazy one idea here) came up with 86
lines of pure assembly (that I will not add here, sorry) that combined with the
rest of our code allowed us to have a working fork of the main process. **MadMan.**

Here's a flow graph from our report showcasing our frida flow.


![alt]({{ site.url }}{{ site.baseurl }}/assets/images/imgs/frida.png)

### The Template System

We built a template system using Jinja2 to generate Frida scripts on the fly:

```
import { Fuzzer } from "./fuzzer.js";

// The custom fuzzer needs to subclass the Fuzzer class to work properly.
class TestFuzzer extends Fuzzer {
    constructor() {
        
        const proc_fn_addr = ptr("{{ function_type }}");

        // Hook on target function.
        const proc_fn = new NativeFunction(
            proc_fn_addr,
            "{{ function_address }}", 
        );

    }

    prepare() {
    }

    fuzz(payload, len) {
        this.target_function(
            // Have to use pseudocode otherwise my hosting framework explodes
            // imagine it in js
          FOR each (i, buffer) IN enumerate(buffers):
            IF i == target:
                OUTPUT "payload"
            ELSE:
                IF buffer[0] == "int":
                    OUTPUT "parseInt(this.var_i)"
                ELSE:
                    OUTPUT 'ptr("buffer[1]")'
            ENDIF

            IF NOT last element in buffers:
                OUTPUT ","
            ENDIF
        ENDFOR
        );
    }
}

const f = new TestFuzzer();
rpc.exports.fuzzer = f;
```

Which combined with a "handler" in python to parse and pass params from our gdb
plugin served as base for intercepting basically all the "trivial"/not too
complex functions.

# Lessons Learned: The Hard Way

At the end of the day we found out that you always have some trade-off:
- QEMU: Correct but slow
- ZAFL: Fast but brittle
- Frida: Flexible but with overhead

> In the end, we optimized for usability over raw performance.

Some things still require human insight:
- Identifying interesting functions
- Understanding function signatures
- Dealing with side effects

> You can automate only up to a certain level

# The Final Product: What Guzz Can Do

After four weeks of blood, sweat, and segfaults, we emerged with a tool that:

1. **Integrates seamlessly with GDB** - Just load the plugin and you're ready to
   go
2. **Supports multiple fuzzing approaches** - Choose your own adventure
3. **Handles binary-only targets** - No source code required
4. **Automates harness generation** - Because life's too short for manual
   harnesses

## Real-World Usage (show off)

Couple example showcase can be found at [Demos](https://github.com/ThomasAndreatta/ThomasAndreatta.github.io/tree/master/assets/video/guzz).
These are video done with the initial version of Guzz, currently I do not have
it installed and I ain't gonna install AFL++ and frida rn, sorry not sorry.


# Conclusion: Was It Worth It?

Absolutely. Guzz proves that the gap between debugging and fuzzing can be
bridged. It's not perfect - we still struggle with certain edge cases, and
multi-threaded applications remain our white whale. But for the common case of
"I found an interesting function and want to fuzz it," Guzz delivers.

And on the human side, we spent 4 weeks non-stop (gonna attach some proofs)
working on something we never thought we would end up doing (fuzzing), but we
had so much fun collaborating as a team, we had such a great workflow and energy
togheter that it propagated to other courses with group assignments and personal
projects togheter, what a blast.

> The code is currently in a private repository (not production ready),
> but if you're interested or want to contribute, feel free reach out!

![alt text]({{ site.url }}{{ site.baseurl }}/assets/images/nuke.png)
![alt text]({{ site.url }}{{ site.baseurl }}/assets/images/funny.png)